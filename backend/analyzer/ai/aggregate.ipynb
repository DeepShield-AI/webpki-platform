{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cert_fingerprint.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_verify = pd.read_csv(\"./cert_pem_results.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['info', 'warn', 'error', 'fatal']\n",
    "total_rows = len(df_verify)\n",
    "\n",
    "for col in columns:\n",
    "    non_zero_count = (df_verify[col] != 0).sum()\n",
    "    proportion = non_zero_count / total_rows\n",
    "    print(f'Column {col}: {non_zero_count}/{total_rows} {proportion}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cert_id = df['CERT_ID']\n",
    "fingerprint_cols = df.columns[df.columns.str.startswith('FINGERPRINT_')]\n",
    "fingerprint_data = df[fingerprint_cols]\n",
    "data = fingerprint_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest(contamination=0.03, random_state=42)\n",
    "iso_forest.fit(data_scaled)\n",
    "df['IF_SCORE'] = iso_forest.decision_function(data_scaled)\n",
    "df['IF_LABEL'] = iso_forest.predict(data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_if = df[df['IF_LABEL'] == -1]\n",
    "print(\"Isolation Forest detected anomalies:\")\n",
    "print(anomalies_if[['CERT_ID']])\n",
    "print(len(anomalies_if))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cert = df_verify[df_verify['error'] != 0]\n",
    "print(error_cert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest_df = pd.concat([df['CERT_ID'],df['IF_LABEL']], axis=1)\n",
    "iso_forest_df.to_csv(\"cert_if.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(base_df, test_df, test_col):\n",
    "    merged_df = pd.merge(base_df, test_df, on='cert_id', how='inner')\n",
    "    base_col = 'error'\n",
    "    TP = len(merged_df[(merged_df[base_col] != 0) & (merged_df[test_col] == -1)])\n",
    "    \n",
    "    # TN: base_col 阴性, test_col 阴性\n",
    "    TN = len(merged_df[(merged_df[base_col] == 0) & (merged_df[test_col] != -1)])\n",
    "    \n",
    "    # FP: base_col 阴性, test_col 阳性\n",
    "    FP = len(merged_df[(merged_df[base_col] == 0) & (merged_df[test_col] == -1)])\n",
    "    \n",
    "    # FN: base_col 阳性, test_col 阴性\n",
    "    FN = len(merged_df[(merged_df[base_col] != 0) & (merged_df[test_col] != -1)])\n",
    "\n",
    "    print(\"TN:\",TN,\"FP:\",FP)\n",
    "    print(\"FN:\",FN,\"TP:\",TP)\n",
    "    print (\"TPR:\",TP/(TP+FN))\n",
    "    print (\"TNR:\",TN/(TN+FP))\n",
    "    print (\"FPR:\",FP/(TN+FP))\n",
    "    print (\"FNR:\",FN/(TP+FN))\n",
    "    \n",
    "    return (TN, TP, FN, FP, FP/(TN+FP), TP/(TP+FN))\n",
    "\n",
    "test_df = iso_forest_df.rename(columns={'CERT_ID': 'cert_id'})\n",
    "tn,tp,fn,fp,_,_ = get_accuracy(df_verify[['cert_id','error']],test_df[['cert_id','IF_LABEL']],'IF_LABEL') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(n_neighbors=10, contamination=0.03)\n",
    "df['LOF_SCORE'] = lof.fit_predict(data_scaled)\n",
    "df['LOF_SCORE'] = -lof.negative_outlier_factor_\n",
    "\n",
    "threshold = sorted(df['LOF_SCORE'], reverse=True)[int(len(df) * 0.03) - 1]\n",
    "df['LOF_LABEL'] = df['LOF_SCORE'] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_df = pd.concat([df['CERT_ID'],df['LOF_LABEL']], axis=1)\n",
    "lof_df.loc[lof_df['LOF_LABEL'],\"LOF_LABEL\"]=-1\n",
    "lof_df.loc[lof_df['LOF_LABEL']==False,\"LOF_LABEL\"]=1\n",
    "lof_df.to_csv(\"cert_lof.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = lof_df.rename(columns={'CERT_ID': 'cert_id'})\n",
    "tn,tp,fn,fp,_,_ = get_accuracy(df_verify[['cert_id','error']],test_df[['cert_id','LOF_LABEL']],'LOF_LABEL') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
